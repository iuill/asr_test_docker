services:
  # =============================================================================
  # Web UI (共通フロントエンド)
  # =============================================================================
  webui:
    build:
      context: ./services/webui
      dockerfile: Dockerfile
    ports:
      - "13800:8000"
    depends_on:
      - k2-v2
      - espnet-v2
      - espnet-v2-onnx
      - google-stt-v1
      - google-stt-chirp2
      - google-stt-chirp3
      - azure-stt
      - azure-stt-diarization
      - openai-stt
    restart: unless-stopped

  # Web UI for CPU-only mode
  webui-cpu:
    build:
      context: ./services/webui
      dockerfile: Dockerfile
    ports:
      - "13800:8000"
    depends_on:
      - k2-v2-cpu
      - espnet-v2-cpu
      - espnet-v2-onnx-cpu
      - google-stt-v1
      - google-stt-chirp2
      - google-stt-chirp3
      - azure-stt
      - azure-stt-diarization
      - openai-stt
    environment:
      - K2_V2_URL=http://k2-v2-cpu:8000
      - ESPNET_V2_URL=http://espnet-v2-cpu:8000
      - ESPNET_V2_ONNX_URL=http://espnet-v2-onnx-cpu:8000
    profiles:
      - cpu
    restart: unless-stopped

  # =============================================================================
  # reazonspeech-k2-v2 (sherpa-onnx based)
  # =============================================================================

  # GPU version (default)
  k2-v2:
    build:
      context: ./services/k2-v2
      dockerfile: Dockerfile
    expose:
      - "8000"
    volumes:
      - k2-v2-model-cache:/root/.cache/huggingface
    environment:
      - HF_HOME=/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped

  # CPU version (alternative)
  k2-v2-cpu:
    build:
      context: ./services/k2-v2
      dockerfile: Dockerfile.cpu
    expose:
      - "8000"
    volumes:
      - k2-v2-model-cache:/root/.cache/huggingface
    environment:
      - HF_HOME=/root/.cache/huggingface
    profiles:
      - cpu
    restart: unless-stopped

  # =============================================================================
  # reazonspeech-espnet-v2 (ESPnet based)
  # =============================================================================

  # GPU version
  espnet-v2:
    build:
      context: ./services/espnet-v2
      dockerfile: Dockerfile
    expose:
      - "8000"
    volumes:
      - espnet-v2-model-cache:/root/.cache/huggingface
      - espnet-v2-torch-cache:/root/.cache/torch
    environment:
      - HF_HOME=/root/.cache/huggingface
      - TORCH_HOME=/root/.cache/torch
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped

  # CPU version (alternative)
  espnet-v2-cpu:
    build:
      context: ./services/espnet-v2
      dockerfile: Dockerfile.cpu
    expose:
      - "8000"
    volumes:
      - espnet-v2-model-cache:/root/.cache/huggingface
      - espnet-v2-torch-cache:/root/.cache/torch
    environment:
      - HF_HOME=/root/.cache/huggingface
      - TORCH_HOME=/root/.cache/torch
    profiles:
      - cpu
    restart: unless-stopped

  # =============================================================================
  # reazonspeech-espnet-v2-onnx (ESPnet ONNX based - High Performance)
  # =============================================================================

  # GPU version
  espnet-v2-onnx:
    build:
      context: ./services/espnet-v2-onnx
      dockerfile: Dockerfile
    expose:
      - "8000"
    volumes:
      - espnet-v2-onnx-model-cache:/root/.cache/huggingface
      - ./cache/espnet_onnx:/root/.cache/espnet_onnx
      - espnet-v2-onnx-torch-cache:/root/.cache/torch
    environment:
      - HF_HOME=/root/.cache/huggingface
      - ESPNET_ONNX_CACHE=/root/.cache/espnet_onnx
      - TORCH_HOME=/root/.cache/torch
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped

  # CPU version (alternative)
  espnet-v2-onnx-cpu:
    build:
      context: ./services/espnet-v2-onnx
      dockerfile: Dockerfile.cpu
    expose:
      - "8000"
    volumes:
      - espnet-v2-onnx-model-cache:/root/.cache/huggingface
      - ./cache/espnet_onnx:/root/.cache/espnet_onnx
      - espnet-v2-onnx-torch-cache:/root/.cache/torch
    environment:
      - HF_HOME=/root/.cache/huggingface
      - ESPNET_ONNX_CACHE=/root/.cache/espnet_onnx
      - TORCH_HOME=/root/.cache/torch
    profiles:
      - cpu
    restart: unless-stopped

  # =============================================================================
  # Google Speech-to-Text V1 (default model)
  # =============================================================================
  google-stt-v1:
    build:
      context: ./services/google-stt-v1
      dockerfile: Dockerfile
    expose:
      - "8000"
    volumes:
      - ./credentials:/credentials:ro
    environment:
      - GOOGLE_APPLICATION_CREDENTIALS=/credentials/google-stt-credentials.json
      - LANGUAGE_CODE=ja-JP
      - ENABLE_PUNCTUATION=true
      - ENABLE_DIARIZATION=true
      - DIARIZATION_SPEAKER_COUNT=2
      - GOOGLE_STT_MODEL=default
    restart: unless-stopped

  # =============================================================================
  # Google Speech-to-Text V2 API (Chirp 2 model)
  # =============================================================================
  google-stt-chirp2:
    build:
      context: ./services/google-stt-v2
      dockerfile: Dockerfile
    expose:
      - "8000"
    volumes:
      - ./credentials:/credentials:ro
    environment:
      - GOOGLE_APPLICATION_CREDENTIALS=/credentials/google-stt-credentials.json
      - LANGUAGE_CODE=ja-JP
      - GOOGLE_STT_LOCATION=asia-southeast1
      - ENABLE_PUNCTUATION=true
      - ENABLE_DIARIZATION=false
      - DIARIZATION_SPEAKER_COUNT=2
      - GOOGLE_STT_MODEL=chirp_2
    restart: unless-stopped

  # =============================================================================
  # Google Speech-to-Text V2 API (Chirp 3 model)
  # =============================================================================
  google-stt-chirp3:
    build:
      context: ./services/google-stt-v2
      dockerfile: Dockerfile
    expose:
      - "8000"
    volumes:
      - ./credentials:/credentials:ro
    environment:
      - GOOGLE_APPLICATION_CREDENTIALS=/credentials/google-stt-credentials.json
      - LANGUAGE_CODE=ja-JP
      - GOOGLE_STT_LOCATION=asia-south1
      - ENABLE_PUNCTUATION=true
      - ENABLE_DIARIZATION=false
      - DIARIZATION_SPEAKER_COUNT=2
      - GOOGLE_STT_MODEL=chirp_3
    restart: unless-stopped

  # =============================================================================
  # Azure Speech-to-Text (Azure AI Speech SDK)
  # =============================================================================
  azure-stt:
    build:
      context: ./services/azure-stt
      dockerfile: Dockerfile
    expose:
      - "8000"
    environment:
      - AZURE_SPEECH_KEY=${AZURE_SPEECH_KEY}
      - AZURE_SPEECH_REGION=${AZURE_SPEECH_REGION:-japaneast}
      - LANGUAGE_CODE=ja-JP
      - ENABLE_PUNCTUATION=true
    restart: unless-stopped

  # =============================================================================
  # Azure Speech-to-Text with Speaker Diarization (ConversationTranscriber)
  # =============================================================================
  azure-stt-diarization:
    build:
      context: ./services/azure-stt-diarization
      dockerfile: Dockerfile
    expose:
      - "8000"
    environment:
      - AZURE_SPEECH_KEY=${AZURE_SPEECH_KEY}
      - AZURE_SPEECH_REGION=${AZURE_SPEECH_REGION:-japaneast}
      - LANGUAGE_CODE=ja-JP
      - ENABLE_PUNCTUATION=true
    restart: unless-stopped

  # =============================================================================
  # OpenAI Speech-to-Text (gpt-4o-transcribe)
  # =============================================================================
  openai-stt:
    build:
      context: ./services/openai-stt
      dockerfile: Dockerfile
    expose:
      - "8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=gpt-4o-transcribe
      - LANGUAGE_CODE=ja
    restart: unless-stopped

volumes:
  k2-v2-model-cache:
  espnet-v2-model-cache:
  espnet-v2-torch-cache:
  espnet-v2-onnx-model-cache:
  espnet-v2-onnx-torch-cache:
