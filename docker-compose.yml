services:
  # =============================================================================
  # Web UI (共通フロントエンド)
  # =============================================================================
  webui:
    build:
      context: ./services/webui
      dockerfile: Dockerfile
    ports:
      - "13800:8000"
    depends_on:
      - k2-v2
      - espnet-v2
      - espnet-v2-onnx
      - google-stt
      - openai-stt
    restart: unless-stopped

  # Web UI for CPU-only mode
  webui-cpu:
    build:
      context: ./services/webui
      dockerfile: Dockerfile
    ports:
      - "13800:8000"
    depends_on:
      - k2-v2-cpu
      - espnet-v2-cpu
      - espnet-v2-onnx-cpu
      - google-stt
      - openai-stt
    profiles:
      - cpu
    restart: unless-stopped

  # =============================================================================
  # reazonspeech-k2-v2 (sherpa-onnx based)
  # =============================================================================

  # GPU version (default)
  k2-v2:
    build:
      context: ./services/k2-v2
      dockerfile: Dockerfile
    expose:
      - "8000"
    volumes:
      - k2-v2-model-cache:/root/.cache/huggingface
    environment:
      - HF_HOME=/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped

  # CPU version (alternative)
  k2-v2-cpu:
    build:
      context: ./services/k2-v2
      dockerfile: Dockerfile.cpu
    expose:
      - "8000"
    volumes:
      - k2-v2-model-cache:/root/.cache/huggingface
    environment:
      - HF_HOME=/root/.cache/huggingface
    profiles:
      - cpu
    restart: unless-stopped

  # =============================================================================
  # reazonspeech-espnet-v2 (ESPnet based)
  # =============================================================================

  # GPU version
  espnet-v2:
    build:
      context: ./services/espnet-v2
      dockerfile: Dockerfile
    expose:
      - "8000"
    volumes:
      - espnet-v2-model-cache:/root/.cache/huggingface
      - espnet-v2-torch-cache:/root/.cache/torch
    environment:
      - HF_HOME=/root/.cache/huggingface
      - TORCH_HOME=/root/.cache/torch
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped

  # CPU version (alternative)
  espnet-v2-cpu:
    build:
      context: ./services/espnet-v2
      dockerfile: Dockerfile.cpu
    expose:
      - "8000"
    volumes:
      - espnet-v2-model-cache:/root/.cache/huggingface
      - espnet-v2-torch-cache:/root/.cache/torch
    environment:
      - HF_HOME=/root/.cache/huggingface
      - TORCH_HOME=/root/.cache/torch
    profiles:
      - cpu
    restart: unless-stopped

  # =============================================================================
  # reazonspeech-espnet-v2-onnx (ESPnet ONNX based - High Performance)
  # =============================================================================

  # GPU version
  espnet-v2-onnx:
    build:
      context: ./services/espnet-v2-onnx
      dockerfile: Dockerfile
    expose:
      - "8000"
    volumes:
      - espnet-v2-onnx-model-cache:/root/.cache/huggingface
      - ./cache/espnet_onnx:/root/.cache/espnet_onnx
      - espnet-v2-onnx-torch-cache:/root/.cache/torch
    environment:
      - HF_HOME=/root/.cache/huggingface
      - ESPNET_ONNX_CACHE=/root/.cache/espnet_onnx
      - TORCH_HOME=/root/.cache/torch
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped

  # CPU version (alternative)
  espnet-v2-onnx-cpu:
    build:
      context: ./services/espnet-v2-onnx
      dockerfile: Dockerfile.cpu
    expose:
      - "8000"
    volumes:
      - espnet-v2-onnx-model-cache:/root/.cache/huggingface
      - ./cache/espnet_onnx:/root/.cache/espnet_onnx
      - espnet-v2-onnx-torch-cache:/root/.cache/torch
    environment:
      - HF_HOME=/root/.cache/huggingface
      - ESPNET_ONNX_CACHE=/root/.cache/espnet_onnx
      - TORCH_HOME=/root/.cache/torch
    profiles:
      - cpu
    restart: unless-stopped

  # =============================================================================
  # Google Speech-to-Text
  # =============================================================================
  google-stt:
    build:
      context: ./services/google-stt
      dockerfile: Dockerfile
    expose:
      - "8000"
    volumes:
      - ./credentials:/credentials:ro
    environment:
      - GOOGLE_APPLICATION_CREDENTIALS=/credentials/google-stt-credentials.json
      - LANGUAGE_CODE=ja-JP
      - ENABLE_PUNCTUATION=true
      - ENABLE_DIARIZATION=true
      - DIARIZATION_SPEAKER_COUNT=2
    restart: unless-stopped

  # =============================================================================
  # OpenAI Speech-to-Text (gpt-4o-transcribe)
  # =============================================================================
  openai-stt:
    build:
      context: ./services/openai-stt
      dockerfile: Dockerfile
    expose:
      - "8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=gpt-4o-transcribe
      - LANGUAGE_CODE=ja
    restart: unless-stopped

volumes:
  k2-v2-model-cache:
  espnet-v2-model-cache:
  espnet-v2-torch-cache:
  espnet-v2-onnx-model-cache:
  espnet-v2-onnx-torch-cache:
